{
  "name": "voicenotesai",
  "displayName": "VoiceNotes AI",
  "description": "Multilingual AI voice transcription and intelligent note-taking for VS Code - captures Zoom, YouTube, conversations",
  "version": "1.0.0",
  "publisher": "hhdao",
  "engines": {
    "vscode": "^1.80.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Notebooks"
  ],
  "keywords": [
    "ai",
    "voice",
    "transcription",
    "notes",
    "whisper",
    "multilingual",
    "zoom",
    "meetings",
    "ambient",
    "conversations"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "voicenotesai.startListening",
        "title": "üé§ Start Voice Recording",
        "category": "VoiceNotes AI"
      },
      {
        "command": "voicenotesai.stopListening",
        "title": "‚èπÔ∏è Stop Voice Recording",
        "category": "VoiceNotes AI"
      },
      {
        "command": "voicenotesai.openPanel",
        "title": "üìù Open Voice Notes Panel",
        "category": "VoiceNotes AI"
      },
      {
        "command": "voicenotesai.transcribeAudioFile",
        "title": "üîä Transcribe Audio File",
        "category": "VoiceNotes AI"
      },
      {
        "command": "voicenotesai.generateSummary",
        "title": "‚ú® Generate AI Summary",
        "category": "VoiceNotes AI"
      },
      {
        "command": "voicenotesai.toggleAmbientListening",
        "title": "üåç Toggle Ambient Listening",
        "category": "VoiceNotes AI"
      }
    ],
    "keybindings": [
      {
        "command": "voicenotesai.startListening",
        "key": "ctrl+shift+v",
        "mac": "cmd+shift+v"
      },
      {
        "command": "voicenotesai.stopListening",
        "key": "ctrl+shift+s",
        "mac": "cmd+shift+s"
      },
      {
        "command": "voicenotesai.toggleAmbientListening",
        "key": "ctrl+shift+a",
        "mac": "cmd+shift+a"
      }
    ],
    "viewsContainers": {
      "activitybar": [
        {
          "id": "voicenotesai",
          "title": "Voice Notes AI",
          "icon": "$(record)"
        }
      ]
    },
    "views": {
      "voicenotesai": [
        {
          "id": "voiceNotesPanel",
          "name": "Transcription",
          "type": "webview"
        },
        {
          "id": "voiceNotesHistory",
          "name": "Voice Notes History",
          "type": "tree"
        }
      ]
    },
    "configuration": {
      "title": "VoiceNotes AI",
      "properties": {
        "voicenotesai.defaultLanguage": {
          "type": "string",
          "default": "auto",
          "description": "Default language for transcription (auto-detect or specific language code like 'en', 'es', 'fr', etc.)"
        },
        "voicenotesai.whisperModel": {
          "type": "string",
          "default": "base",
          "enum": [
            "tiny",
            "base",
            "small",
            "medium",
            "large"
          ],
          "description": "Whisper model size (larger = more accurate but slower)"
        },
        "voicenotesai.enableAmbientListening": {
          "type": "boolean",
          "default": false,
          "description": "Enable continuous ambient conversation listening (captures all audio around device)"
        },
        "voicenotesai.autoSummarize": {
          "type": "boolean",
          "default": true,
          "description": "Automatically generate AI summaries after transcription"
        },
        "voicenotesai.saveTranscripts": {
          "type": "boolean",
          "default": true,
          "description": "Save transcripts to workspace .voicenotes folder"
        },
        "voicenotesai.ollamaModel": {
          "type": "string",
          "default": "llama3.2",
          "description": "Ollama model for summarization and note generation"
        },
        "voicenotesai.captureSystemAudio": {
          "type": "boolean",
          "default": true,
          "description": "Capture system audio (Zoom calls, YouTube, etc.) in addition to microphone"
        },
        "voicenotesai.realTimeTranscription": {
          "type": "boolean",
          "default": true,
          "description": "Show real-time transcription as you speak"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@playwright/test": "^1.55.1",
    "@types/node": "^18.x",
    "@types/vscode": "^1.80.0",
    "@typescript-eslint/eslint-plugin": "^5.x",
    "@typescript-eslint/parser": "^5.x",
    "eslint": "^8.x",
    "typescript": "^5.1.6"
  },
  "dependencies": {
    "axios": "^1.5.0",
    "form-data": "^4.0.0",
    "ws": "^8.13.0"
  }
}
